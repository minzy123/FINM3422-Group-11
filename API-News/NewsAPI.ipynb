{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a2f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (2025.1.31)\n",
      "Requirement already satisfied: key in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.4)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: bs4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->bs4) (4.12.2)\n",
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 DDoS Mitigation Leak\n",
      "1 Tech, Media & Telecom Roundup: Market Talk\n",
      "2 Inaki Berroeta Buys 335,102 Shares of TPG Telecom Limited (ASX:TPG) Stock\n",
      "3 In Memoriam: The 31 Billionaires Who Died Over The Past Year\n",
      "4 Singapore Telecoms Industry Report 2025, with Detailed Operator Profiles and Forecasts for Singtel, Starhub, M1 and Simba\n",
      "5 2 ASX growth shares I'd buy to try to beat the market\n",
      "6 Should I buy Brickworks or Soul Patts shares?\n",
      "7 If I could only own 1 ASX stock, it would be this one\n",
      "8 2 ASX shares I think are fantastic for beginners\n",
      "9 Australia’s TPG yearns for the simple life\n",
      "10 [NANOG] Weekly Global IPv4 Routing Table Report\n",
      "11 [NANOG] Weekly Global IPv4 Routing Table Report\n",
      "12 [NANOG] Weekly Global IPv4 Routing Table Report\n",
      "13 China Mobile stakes a claim on HKBN\n",
      "14 Satellite and 6G technology set to revolutionise emergency services\n",
      "\n",
      "source         {'id': None, 'name': 'Kentik.com'}\n",
      "\n",
      "author         None\n",
      "\n",
      "title          DDoS Mitigation Leak\n",
      "\n",
      "description    In this edition of Beyond Their Intended Scope, we take a look at last week’s BGP leak by a DDoS mitigation company which impacted networks around the world. We look at the impacts in both BGP and traffic data, and discuss how RFC 9234’s “Only to Customer” BG…\n",
      "\n",
      "url            https://www.kentik.com/blog/beyond-their-intended-scope-ddos-mitigation-leak/\n",
      "\n",
      "urlToImage     https://images.ctfassets.net/6yom6slo28h2/42btGaEeULlyrQZ6hNslqc/f59dd066fca746b42f1e160fe6e5c90a/beyond-their-intended-scope-voxility.png\n",
      "\n",
      "publishedAt    2025-04-08T17:41:24Z\n",
      "\n",
      "content        SubscribeSummary\n",
      "In this edition of Beyond Their Intended Scope, we take a look at last weeks BGP leak by a DDoS mitigation company which impacted networks around the world. We look at the impacts i… [+11797 chars]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 130, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 130, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 130, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 130, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
     ]
    }
   ],
   "source": [
    "# Install and import News API and other necessary Python librarires\n",
    "!pip install newsapi-python\n",
    "!pip install key\n",
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install transformers\n",
    "from newsapi import NewsApiClient\n",
    "from key import my_api_key\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "# Remove character limit for data frames\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Link API to API key and define as a variable\n",
    "newsapi = NewsApiClient(api_key = my_api_key)\n",
    "\n",
    "# Generate recent news articles in English regarding \"TPG Telecom\"\n",
    "data = newsapi.get_everything(q='TPG Telecom', language = 'en')\n",
    "\n",
    "# Define a variable for the generated articles\n",
    "articles = data['articles']\n",
    "\n",
    "# Format and number collected articles\n",
    "for x,y in enumerate(articles):\n",
    "    print(f'{x} {y[\"title\"]}') \n",
    "for key, value in articles[0].items():\n",
    "    print(f\"\\n{key.ljust(15)}{value}\")\n",
    "\n",
    "# Create a data frame for the articles\n",
    "df = pd.DataFrame(articles)\n",
    "\n",
    "# Remove all information except for url to articles\n",
    "website_links = df['url']\n",
    "\n",
    "# Set up AI text summarisation model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define a function which applies the summarisation model to url inputs\n",
    "def summarise_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        title = soup.title.string if soup.title else 'No Title'\n",
    "        para = soup.find_all('p')\n",
    "        text = ''.join(p.get_text() for p in para)\n",
    "\n",
    "        text = text[:3000]\n",
    "\n",
    "        summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error summarisng: {e}\"\n",
    "    \n",
    "# Apply the summarisation function to the series containing the links to articles\n",
    "website_links['summary'] = df['url'].apply(summarise_url)\n",
    "\n",
    "# Define the summary of links\n",
    "TPG_summary = website_links['summary']\n",
    "\n",
    "# As some news cites are whitelisted from news APIs (CNN), create a variable containing the keywords 'Error' and 'CNN' so they can be removed\n",
    "keywords = ['Error', 'CNN']\n",
    "\n",
    "# Refine the series of summaries to remove any summaries which have errors or are by CNN\n",
    "refined_summary = TPG_summary[~TPG_summary.astype(str).apply(\n",
    "    lambda x: any(kw in x for kw in keywords)\n",
    ")]\n",
    "\n",
    "# Redefine the series so there are no spaces in the data frame\n",
    "refined_summary = refined_summary.loc[[2,4,9,14]]\n",
    "\n",
    "# Rewrite the series so that they are in the same cell but separated by paragraphs\n",
    "refined_summary = \"\\n\\n\".join(TPG_summary.loc[[2,4,9,14]])\n",
    "\n",
    "# Filter out any characters that are not readable\n",
    "TPG_summary_text = refined_summary.encode('latin-1', 'ignore').decode('latin-1')\n",
    "\n",
    "# Create a txt document in the 'Main PDF + Images' folder with the final recent news summaries\n",
    "file_path = \"/workspaces/FINM3422-Group-11/Main PDF + Images/TPG_summary_text.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(TPG_summary_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
